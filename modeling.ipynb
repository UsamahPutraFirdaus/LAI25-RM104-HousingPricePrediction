{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "04565d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "50677e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data_Lamudi_Cleaned.csv')\n",
    "\n",
    "# Fitur (X) dan target (y)\n",
    "fitur = ['Kamar Tidur', 'Kamar Mandi', 'Luas Bangunan', 'Luas Tanah']\n",
    "X = df[fitur]\n",
    "y = df['Harga']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4533e06c",
   "metadata": {},
   "source": [
    "# Membuat model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74747b42",
   "metadata": {},
   "source": [
    "## Linear Regression, Random Forest, XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d0631c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardisasi fitur (hanya untuk Linear Regression)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Definisikan model\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Random Forest\": RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    \"XGBoost\": XGBRegressor(objective='reg:squarederror', n_estimators=100, random_state=42)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "636e0108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Linear Regression...\n",
      "\n",
      "Training Random Forest...\n",
      "\n",
      "Training XGBoost...\n"
     ]
    }
   ],
   "source": [
    "# Training & Evaluasi\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    \n",
    "    # Gunakan fitur yang sudah distandardisasi hanya untuk Linear Regression\n",
    "    if name == \"Linear Regression\":\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    results[name] = {\"RMSE\": rmse, \"R2\": r2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "01bad521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluasi Model ---\n",
      "Linear Regression - RMSE: 584409864.50, R2: 0.7485\n",
      "Random Forest - RMSE: 726208194.12, R2: 0.6116\n",
      "XGBoost - RMSE: 833833423.18, R2: 0.4879\n"
     ]
    }
   ],
   "source": [
    "# Tampilkan hasil evaluasi\n",
    "print(\"\\n--- Evaluasi Model ---\")\n",
    "for name, res in results.items():\n",
    "    print(f\"{name} - RMSE: {res['RMSE']:.2f}, R2: {res['R2']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c3e5bd",
   "metadata": {},
   "source": [
    "## Neural Network (Tensorflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ffbcec11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Koding\\Laskar AI\\Laskar_AI_CapstonProject\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - loss: 445.3582 - val_loss: 443.7501 - learning_rate: 1.0000e-04\n",
      "Epoch 2/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 440.1816 - val_loss: 439.6168 - learning_rate: 1.0000e-04\n",
      "Epoch 3/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 436.2153 - val_loss: 435.3862 - learning_rate: 1.0000e-04\n",
      "Epoch 4/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 431.5794 - val_loss: 430.9203 - learning_rate: 1.0000e-04\n",
      "Epoch 5/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 426.8196 - val_loss: 426.0940 - learning_rate: 1.0000e-04\n",
      "Epoch 6/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 421.4251 - val_loss: 420.7545 - learning_rate: 1.0000e-04\n",
      "Epoch 7/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 415.2963 - val_loss: 414.8084 - learning_rate: 1.0000e-04\n",
      "Epoch 8/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 409.6981 - val_loss: 408.0827 - learning_rate: 1.0000e-04\n",
      "Epoch 9/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 401.4263 - val_loss: 400.5717 - learning_rate: 1.0000e-04\n",
      "Epoch 10/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 393.7026 - val_loss: 392.2715 - learning_rate: 1.0000e-04\n",
      "Epoch 11/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 384.6028 - val_loss: 383.0171 - learning_rate: 1.0000e-04\n",
      "Epoch 12/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 374.8789 - val_loss: 372.6961 - learning_rate: 1.0000e-04\n",
      "Epoch 13/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 364.7844 - val_loss: 361.3444 - learning_rate: 1.0000e-04\n",
      "Epoch 14/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 352.8620 - val_loss: 348.9868 - learning_rate: 1.0000e-04\n",
      "Epoch 15/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 339.4192 - val_loss: 335.6144 - learning_rate: 1.0000e-04\n",
      "Epoch 16/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 325.9552 - val_loss: 321.1971 - learning_rate: 1.0000e-04\n",
      "Epoch 17/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 311.1320 - val_loss: 305.7853 - learning_rate: 1.0000e-04\n",
      "Epoch 18/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 296.1458 - val_loss: 289.3834 - learning_rate: 1.0000e-04\n",
      "Epoch 19/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 280.2575 - val_loss: 272.2546 - learning_rate: 1.0000e-04\n",
      "Epoch 20/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 259.9187 - val_loss: 254.3958 - learning_rate: 1.0000e-04\n",
      "Epoch 21/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 244.3909 - val_loss: 236.1359 - learning_rate: 1.0000e-04\n",
      "Epoch 22/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 223.6313 - val_loss: 217.6440 - learning_rate: 1.0000e-04\n",
      "Epoch 23/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 207.2298 - val_loss: 199.2437 - learning_rate: 1.0000e-04\n",
      "Epoch 24/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 188.2189 - val_loss: 181.1697 - learning_rate: 1.0000e-04\n",
      "Epoch 25/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 170.6709 - val_loss: 163.7518 - learning_rate: 1.0000e-04\n",
      "Epoch 26/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 155.7346 - val_loss: 147.3530 - learning_rate: 1.0000e-04\n",
      "Epoch 27/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 140.0217 - val_loss: 132.2026 - learning_rate: 1.0000e-04\n",
      "Epoch 28/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 126.9289 - val_loss: 118.3987 - learning_rate: 1.0000e-04\n",
      "Epoch 29/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 112.4326 - val_loss: 106.2667 - learning_rate: 1.0000e-04\n",
      "Epoch 30/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 100.9096 - val_loss: 95.7418 - learning_rate: 1.0000e-04\n",
      "Epoch 31/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 92.8414 - val_loss: 86.8229 - learning_rate: 1.0000e-04\n",
      "Epoch 32/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 85.0256 - val_loss: 79.4082 - learning_rate: 1.0000e-04\n",
      "Epoch 33/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 78.7770 - val_loss: 73.2893 - learning_rate: 1.0000e-04\n",
      "Epoch 34/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 75.4627 - val_loss: 68.4228 - learning_rate: 1.0000e-04\n",
      "Epoch 35/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 72.9527 - val_loss: 64.7040 - learning_rate: 1.0000e-04\n",
      "Epoch 36/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 70.2274 - val_loss: 61.7082 - learning_rate: 1.0000e-04\n",
      "Epoch 37/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 63.7847 - val_loss: 59.1511 - learning_rate: 1.0000e-04\n",
      "Epoch 38/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 64.8507 - val_loss: 57.0337 - learning_rate: 1.0000e-04\n",
      "Epoch 39/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 59.5054 - val_loss: 55.3384 - learning_rate: 1.0000e-04\n",
      "Epoch 40/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 58.5913 - val_loss: 53.8716 - learning_rate: 1.0000e-04\n",
      "Epoch 41/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 57.1189 - val_loss: 52.5162 - learning_rate: 1.0000e-04\n",
      "Epoch 42/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 55.8873 - val_loss: 51.2355 - learning_rate: 1.0000e-04\n",
      "Epoch 43/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 55.9513 - val_loss: 50.0820 - learning_rate: 1.0000e-04\n",
      "Epoch 44/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 56.9940 - val_loss: 49.0212 - learning_rate: 1.0000e-04\n",
      "Epoch 45/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 51.6429 - val_loss: 47.9480 - learning_rate: 1.0000e-04\n",
      "Epoch 46/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 55.4754 - val_loss: 46.9635 - learning_rate: 1.0000e-04\n",
      "Epoch 47/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 51.2504 - val_loss: 46.0113 - learning_rate: 1.0000e-04\n",
      "Epoch 48/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 47.6580 - val_loss: 45.0109 - learning_rate: 1.0000e-04\n",
      "Epoch 49/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 48.6606 - val_loss: 44.0435 - learning_rate: 1.0000e-04\n",
      "Epoch 50/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 47.0835 - val_loss: 43.1110 - learning_rate: 1.0000e-04\n",
      "Epoch 51/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 47.7299 - val_loss: 42.1878 - learning_rate: 1.0000e-04\n",
      "Epoch 52/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 46.3356 - val_loss: 41.2861 - learning_rate: 1.0000e-04\n",
      "Epoch 53/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 45.5881 - val_loss: 40.4033 - learning_rate: 1.0000e-04\n",
      "Epoch 54/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 45.7975 - val_loss: 39.5761 - learning_rate: 1.0000e-04\n",
      "Epoch 55/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 46.3990 - val_loss: 38.7382 - learning_rate: 1.0000e-04\n",
      "Epoch 56/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 41.6876 - val_loss: 37.8922 - learning_rate: 1.0000e-04\n",
      "Epoch 57/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 41.8644 - val_loss: 37.0404 - learning_rate: 1.0000e-04\n",
      "Epoch 58/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 41.1816 - val_loss: 36.2508 - learning_rate: 1.0000e-04\n",
      "Epoch 59/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 39.2330 - val_loss: 35.5049 - learning_rate: 1.0000e-04\n",
      "Epoch 60/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 38.9357 - val_loss: 34.7731 - learning_rate: 1.0000e-04\n",
      "Epoch 61/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 37.3687 - val_loss: 34.0765 - learning_rate: 1.0000e-04\n",
      "Epoch 62/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 38.1524 - val_loss: 33.4078 - learning_rate: 1.0000e-04\n",
      "Epoch 63/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 36.6882 - val_loss: 32.7353 - learning_rate: 1.0000e-04\n",
      "Epoch 64/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 35.7846 - val_loss: 32.0473 - learning_rate: 1.0000e-04\n",
      "Epoch 65/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 36.1790 - val_loss: 31.3838 - learning_rate: 1.0000e-04\n",
      "Epoch 66/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 36.3308 - val_loss: 30.7874 - learning_rate: 1.0000e-04\n",
      "Epoch 67/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 34.9981 - val_loss: 30.1935 - learning_rate: 1.0000e-04\n",
      "Epoch 68/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 32.7400 - val_loss: 29.5546 - learning_rate: 1.0000e-04\n",
      "Epoch 69/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 33.3912 - val_loss: 28.9800 - learning_rate: 1.0000e-04\n",
      "Epoch 70/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 32.9773 - val_loss: 28.4787 - learning_rate: 1.0000e-04\n",
      "Epoch 71/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 30.5927 - val_loss: 27.9741 - learning_rate: 1.0000e-04\n",
      "Epoch 72/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 32.8241 - val_loss: 27.4315 - learning_rate: 1.0000e-04\n",
      "Epoch 73/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 30.5893 - val_loss: 26.8866 - learning_rate: 1.0000e-04\n",
      "Epoch 74/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 31.0870 - val_loss: 26.3905 - learning_rate: 1.0000e-04\n",
      "Epoch 75/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 27.3389 - val_loss: 25.8939 - learning_rate: 1.0000e-04\n",
      "Epoch 76/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 31.9156 - val_loss: 25.4596 - learning_rate: 1.0000e-04\n",
      "Epoch 77/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 29.9010 - val_loss: 25.0164 - learning_rate: 1.0000e-04\n",
      "Epoch 78/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 27.7786 - val_loss: 24.5702 - learning_rate: 1.0000e-04\n",
      "Epoch 79/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 28.2280 - val_loss: 24.1483 - learning_rate: 1.0000e-04\n",
      "Epoch 80/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 26.5616 - val_loss: 23.6895 - learning_rate: 1.0000e-04\n",
      "Epoch 81/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 27.0594 - val_loss: 23.2290 - learning_rate: 1.0000e-04\n",
      "Epoch 82/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 25.4837 - val_loss: 22.7275 - learning_rate: 1.0000e-04\n",
      "Epoch 83/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 24.2490 - val_loss: 22.2604 - learning_rate: 1.0000e-04\n",
      "Epoch 84/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 26.5547 - val_loss: 21.8224 - learning_rate: 1.0000e-04\n",
      "Epoch 85/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 22.8736 - val_loss: 21.4762 - learning_rate: 1.0000e-04\n",
      "Epoch 86/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 24.6838 - val_loss: 21.1245 - learning_rate: 1.0000e-04\n",
      "Epoch 87/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 23.4538 - val_loss: 20.7170 - learning_rate: 1.0000e-04\n",
      "Epoch 88/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 23.5632 - val_loss: 20.3315 - learning_rate: 1.0000e-04\n",
      "Epoch 89/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 23.7455 - val_loss: 20.0510 - learning_rate: 1.0000e-04\n",
      "Epoch 90/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 23.7586 - val_loss: 19.7995 - learning_rate: 1.0000e-04\n",
      "Epoch 91/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 23.6218 - val_loss: 19.5343 - learning_rate: 1.0000e-04\n",
      "Epoch 92/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 22.2596 - val_loss: 19.1915 - learning_rate: 1.0000e-04\n",
      "Epoch 93/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 22.0181 - val_loss: 18.8304 - learning_rate: 1.0000e-04\n",
      "Epoch 94/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 20.9066 - val_loss: 18.4291 - learning_rate: 1.0000e-04\n",
      "Epoch 95/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 23.6273 - val_loss: 18.1308 - learning_rate: 1.0000e-04\n",
      "Epoch 96/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 21.1594 - val_loss: 17.8687 - learning_rate: 1.0000e-04\n",
      "Epoch 97/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 22.6425 - val_loss: 17.5969 - learning_rate: 1.0000e-04\n",
      "Epoch 98/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 19.7433 - val_loss: 17.2893 - learning_rate: 1.0000e-04\n",
      "Epoch 99/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 20.3981 - val_loss: 16.9714 - learning_rate: 1.0000e-04\n",
      "Epoch 100/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 19.1407 - val_loss: 16.6895 - learning_rate: 1.0000e-04\n",
      "Epoch 101/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 18.6523 - val_loss: 16.4626 - learning_rate: 1.0000e-04\n",
      "Epoch 102/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 19.6732 - val_loss: 16.2472 - learning_rate: 1.0000e-04\n",
      "Epoch 103/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 20.2095 - val_loss: 16.0359 - learning_rate: 1.0000e-04\n",
      "Epoch 104/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 17.3031 - val_loss: 15.8464 - learning_rate: 1.0000e-04\n",
      "Epoch 105/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 19.8040 - val_loss: 15.6180 - learning_rate: 1.0000e-04\n",
      "Epoch 106/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 19.0067 - val_loss: 15.4277 - learning_rate: 1.0000e-04\n",
      "Epoch 107/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 19.6060 - val_loss: 15.1677 - learning_rate: 1.0000e-04\n",
      "Epoch 108/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 18.4639 - val_loss: 14.9195 - learning_rate: 1.0000e-04\n",
      "Epoch 109/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 18.1094 - val_loss: 14.6164 - learning_rate: 1.0000e-04\n",
      "Epoch 110/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 18.2101 - val_loss: 14.2976 - learning_rate: 1.0000e-04\n",
      "Epoch 111/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 17.6066 - val_loss: 13.9995 - learning_rate: 1.0000e-04\n",
      "Epoch 112/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 14.9713 - val_loss: 13.7165 - learning_rate: 1.0000e-04\n",
      "Epoch 113/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 16.3789 - val_loss: 13.3938 - learning_rate: 1.0000e-04\n",
      "Epoch 114/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 17.7481 - val_loss: 13.1550 - learning_rate: 1.0000e-04\n",
      "Epoch 115/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 16.5471 - val_loss: 12.9564 - learning_rate: 1.0000e-04\n",
      "Epoch 116/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 14.7428 - val_loss: 12.7542 - learning_rate: 1.0000e-04\n",
      "Epoch 117/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 15.6011 - val_loss: 12.5702 - learning_rate: 1.0000e-04\n",
      "Epoch 118/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 15.6108 - val_loss: 12.3946 - learning_rate: 1.0000e-04\n",
      "Epoch 119/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 16.2843 - val_loss: 12.2306 - learning_rate: 1.0000e-04\n",
      "Epoch 120/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 15.1947 - val_loss: 12.1038 - learning_rate: 1.0000e-04\n",
      "Epoch 121/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 13.6900 - val_loss: 11.9303 - learning_rate: 1.0000e-04\n",
      "Epoch 122/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 14.5060 - val_loss: 11.7557 - learning_rate: 1.0000e-04\n",
      "Epoch 123/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 13.9173 - val_loss: 11.5841 - learning_rate: 1.0000e-04\n",
      "Epoch 124/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 13.8752 - val_loss: 11.3819 - learning_rate: 1.0000e-04\n",
      "Epoch 125/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 13.8440 - val_loss: 11.1723 - learning_rate: 1.0000e-04\n",
      "Epoch 126/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 15.6195 - val_loss: 10.9199 - learning_rate: 1.0000e-04\n",
      "Epoch 127/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 12.6975 - val_loss: 10.6743 - learning_rate: 1.0000e-04\n",
      "Epoch 128/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 13.2340 - val_loss: 10.4526 - learning_rate: 1.0000e-04\n",
      "Epoch 129/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 13.3639 - val_loss: 10.2779 - learning_rate: 1.0000e-04\n",
      "Epoch 130/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 13.6306 - val_loss: 10.1184 - learning_rate: 1.0000e-04\n",
      "Epoch 131/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 12.4028 - val_loss: 9.9728 - learning_rate: 1.0000e-04\n",
      "Epoch 132/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 14.0258 - val_loss: 9.8384 - learning_rate: 1.0000e-04\n",
      "Epoch 133/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - loss: 12.0913 - val_loss: 9.7072 - learning_rate: 1.0000e-04\n",
      "Epoch 134/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 12.6787 - val_loss: 9.5198 - learning_rate: 1.0000e-04\n",
      "Epoch 135/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 12.8605 - val_loss: 9.3059 - learning_rate: 1.0000e-04\n",
      "Epoch 136/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 12.2162 - val_loss: 9.1216 - learning_rate: 1.0000e-04\n",
      "Epoch 137/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 11.2799 - val_loss: 8.9429 - learning_rate: 1.0000e-04\n",
      "Epoch 138/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 12.0493 - val_loss: 8.7523 - learning_rate: 1.0000e-04\n",
      "Epoch 139/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 10.7647 - val_loss: 8.5562 - learning_rate: 1.0000e-04\n",
      "Epoch 140/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 11.0053 - val_loss: 8.3812 - learning_rate: 1.0000e-04\n",
      "Epoch 141/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 10.8709 - val_loss: 8.2775 - learning_rate: 1.0000e-04\n",
      "Epoch 142/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 12.6513 - val_loss: 8.1747 - learning_rate: 1.0000e-04\n",
      "Epoch 143/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 11.7135 - val_loss: 8.0046 - learning_rate: 1.0000e-04\n",
      "Epoch 144/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 10.9808 - val_loss: 7.8400 - learning_rate: 1.0000e-04\n",
      "Epoch 145/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 11.5072 - val_loss: 7.7097 - learning_rate: 1.0000e-04\n",
      "Epoch 146/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 11.1339 - val_loss: 7.5869 - learning_rate: 1.0000e-04\n",
      "Epoch 147/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 9.9583 - val_loss: 7.4700 - learning_rate: 1.0000e-04\n",
      "Epoch 148/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 10.9464 - val_loss: 7.3368 - learning_rate: 1.0000e-04\n",
      "Epoch 149/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 10.6072 - val_loss: 7.2101 - learning_rate: 1.0000e-04\n",
      "Epoch 150/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 9.0850 - val_loss: 7.1051 - learning_rate: 1.0000e-04\n",
      "Epoch 151/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 9.1101 - val_loss: 6.9997 - learning_rate: 1.0000e-04\n",
      "Epoch 152/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 9.6103 - val_loss: 6.9094 - learning_rate: 1.0000e-04\n",
      "Epoch 153/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 10.0457 - val_loss: 6.8281 - learning_rate: 1.0000e-04\n",
      "Epoch 154/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 9.5435 - val_loss: 6.7053 - learning_rate: 1.0000e-04\n",
      "Epoch 155/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 9.3601 - val_loss: 6.5537 - learning_rate: 1.0000e-04\n",
      "Epoch 156/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 8.3205 - val_loss: 6.4072 - learning_rate: 1.0000e-04\n",
      "Epoch 157/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 9.1956 - val_loss: 6.2774 - learning_rate: 1.0000e-04\n",
      "Epoch 158/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 9.1873 - val_loss: 6.1894 - learning_rate: 1.0000e-04\n",
      "Epoch 159/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 9.8698 - val_loss: 6.0927 - learning_rate: 1.0000e-04\n",
      "Epoch 160/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 8.3186 - val_loss: 5.9821 - learning_rate: 1.0000e-04\n",
      "Epoch 161/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 7.8507 - val_loss: 5.8953 - learning_rate: 1.0000e-04\n",
      "Epoch 162/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 9.6072 - val_loss: 5.8318 - learning_rate: 1.0000e-04\n",
      "Epoch 163/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 9.2033 - val_loss: 5.7263 - learning_rate: 1.0000e-04\n",
      "Epoch 164/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 8.7290 - val_loss: 5.5991 - learning_rate: 1.0000e-04\n",
      "Epoch 165/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 8.6610 - val_loss: 5.4964 - learning_rate: 1.0000e-04\n",
      "Epoch 166/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 8.6225 - val_loss: 5.3878 - learning_rate: 1.0000e-04\n",
      "Epoch 167/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 9.7122 - val_loss: 5.2909 - learning_rate: 1.0000e-04\n",
      "Epoch 168/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 7.6476 - val_loss: 5.1939 - learning_rate: 1.0000e-04\n",
      "Epoch 169/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 8.1317 - val_loss: 5.1063 - learning_rate: 1.0000e-04\n",
      "Epoch 170/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 9.0380 - val_loss: 5.0248 - learning_rate: 1.0000e-04\n",
      "Epoch 171/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 7.5798 - val_loss: 4.9205 - learning_rate: 1.0000e-04\n",
      "Epoch 172/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 8.9431 - val_loss: 4.8423 - learning_rate: 1.0000e-04\n",
      "Epoch 173/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 7.7301 - val_loss: 4.7426 - learning_rate: 1.0000e-04\n",
      "Epoch 174/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 7.5428 - val_loss: 4.6610 - learning_rate: 1.0000e-04\n",
      "Epoch 175/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 6.9679 - val_loss: 4.5739 - learning_rate: 1.0000e-04\n",
      "Epoch 176/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 7.2333 - val_loss: 4.4862 - learning_rate: 1.0000e-04\n",
      "Epoch 177/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 7.4246 - val_loss: 4.4469 - learning_rate: 1.0000e-04\n",
      "Epoch 178/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 7.7174 - val_loss: 4.4220 - learning_rate: 1.0000e-04\n",
      "Epoch 179/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 8.0265 - val_loss: 4.3503 - learning_rate: 1.0000e-04\n",
      "Epoch 180/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 7.7914 - val_loss: 4.2367 - learning_rate: 1.0000e-04\n",
      "Epoch 181/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 7.5801 - val_loss: 4.1359 - learning_rate: 1.0000e-04\n",
      "Epoch 182/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 7.6513 - val_loss: 4.0803 - learning_rate: 1.0000e-04\n",
      "Epoch 183/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 7.0397 - val_loss: 4.0122 - learning_rate: 1.0000e-04\n",
      "Epoch 184/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.8059 - val_loss: 3.9423 - learning_rate: 1.0000e-04\n",
      "Epoch 185/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 7.1645 - val_loss: 3.8685 - learning_rate: 1.0000e-04\n",
      "Epoch 186/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 7.2672 - val_loss: 3.8414 - learning_rate: 1.0000e-04\n",
      "Epoch 187/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 7.2212 - val_loss: 3.8151 - learning_rate: 1.0000e-04\n",
      "Epoch 188/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 7.0002 - val_loss: 3.7267 - learning_rate: 1.0000e-04\n",
      "Epoch 189/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.1721 - val_loss: 3.6134 - learning_rate: 1.0000e-04\n",
      "Epoch 190/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 6.8161 - val_loss: 3.5074 - learning_rate: 1.0000e-04\n",
      "Epoch 191/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 6.4596 - val_loss: 3.4492 - learning_rate: 1.0000e-04\n",
      "Epoch 192/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 6.4976 - val_loss: 3.4204 - learning_rate: 1.0000e-04\n",
      "Epoch 193/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.3997 - val_loss: 3.4203 - learning_rate: 1.0000e-04\n",
      "Epoch 194/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 6.9575 - val_loss: 3.3558 - learning_rate: 1.0000e-04\n",
      "Epoch 195/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.8032 - val_loss: 3.2588 - learning_rate: 1.0000e-04\n",
      "Epoch 196/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.9863 - val_loss: 3.2397 - learning_rate: 1.0000e-04\n",
      "Epoch 197/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 6.6163 - val_loss: 3.1567 - learning_rate: 1.0000e-04\n",
      "Epoch 198/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 6.1646 - val_loss: 3.0774 - learning_rate: 1.0000e-04\n",
      "Epoch 199/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 7.4072 - val_loss: 3.0378 - learning_rate: 1.0000e-04\n",
      "Epoch 200/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 7.0334 - val_loss: 3.0299 - learning_rate: 1.0000e-04\n",
      "Epoch 201/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.8548 - val_loss: 2.9759 - learning_rate: 1.0000e-04\n",
      "Epoch 202/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.8840 - val_loss: 2.9296 - learning_rate: 1.0000e-04\n",
      "Epoch 203/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 5.9478 - val_loss: 2.9065 - learning_rate: 1.0000e-04\n",
      "Epoch 204/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 6.5019 - val_loss: 2.9355 - learning_rate: 1.0000e-04\n",
      "Epoch 205/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 6.7728 - val_loss: 2.8827 - learning_rate: 1.0000e-04\n",
      "Epoch 206/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 6.2743 - val_loss: 2.7895 - learning_rate: 1.0000e-04\n",
      "Epoch 207/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 6.1139 - val_loss: 2.7187 - learning_rate: 1.0000e-04\n",
      "Epoch 208/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 6.8181 - val_loss: 2.6541 - learning_rate: 1.0000e-04\n",
      "Epoch 209/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 5.8884 - val_loss: 2.6085 - learning_rate: 1.0000e-04\n",
      "Epoch 210/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 5.4934 - val_loss: 2.5573 - learning_rate: 1.0000e-04\n",
      "Epoch 211/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 5.4023 - val_loss: 2.5490 - learning_rate: 1.0000e-04\n",
      "Epoch 212/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 6.6458 - val_loss: 2.4865 - learning_rate: 1.0000e-04\n",
      "Epoch 213/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.8657 - val_loss: 2.4705 - learning_rate: 1.0000e-04\n",
      "Epoch 214/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 5.5272 - val_loss: 2.4565 - learning_rate: 1.0000e-04\n",
      "Epoch 215/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 5.2524 - val_loss: 2.4121 - learning_rate: 1.0000e-04\n",
      "Epoch 216/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.0494 - val_loss: 2.3660 - learning_rate: 1.0000e-04\n",
      "Epoch 217/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.8200 - val_loss: 2.3578 - learning_rate: 1.0000e-04\n",
      "Epoch 218/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 5.5083 - val_loss: 2.3121 - learning_rate: 1.0000e-04\n",
      "Epoch 219/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 5.3464 - val_loss: 2.2520 - learning_rate: 1.0000e-04\n",
      "Epoch 220/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 5.9807 - val_loss: 2.2213 - learning_rate: 1.0000e-04\n",
      "Epoch 221/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.2549 - val_loss: 2.2004 - learning_rate: 1.0000e-04\n",
      "Epoch 222/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 5.2896 - val_loss: 2.1952 - learning_rate: 1.0000e-04\n",
      "Epoch 223/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 6.4027 - val_loss: 2.1424 - learning_rate: 1.0000e-04\n",
      "Epoch 224/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 5.3608 - val_loss: 2.1030 - learning_rate: 1.0000e-04\n",
      "Epoch 225/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 5.0138 - val_loss: 2.0430 - learning_rate: 1.0000e-04\n",
      "Epoch 226/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 5.7506 - val_loss: 2.0184 - learning_rate: 1.0000e-04\n",
      "Epoch 227/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 5.8580 - val_loss: 2.0105 - learning_rate: 1.0000e-04\n",
      "Epoch 228/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 5.7148 - val_loss: 2.0107 - learning_rate: 1.0000e-04\n",
      "Epoch 229/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 5.0925 - val_loss: 1.9434 - learning_rate: 1.0000e-04\n",
      "Epoch 230/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.1497 - val_loss: 1.9524 - learning_rate: 1.0000e-04\n",
      "Epoch 231/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 4.3248 - val_loss: 1.9673 - learning_rate: 1.0000e-04\n",
      "Epoch 232/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 5.3878 - val_loss: 1.8813 - learning_rate: 1.0000e-04\n",
      "Epoch 233/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 4.6081 - val_loss: 1.8215 - learning_rate: 1.0000e-04\n",
      "Epoch 234/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 4.8614 - val_loss: 1.7944 - learning_rate: 1.0000e-04\n",
      "Epoch 235/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 5.4730 - val_loss: 1.7926 - learning_rate: 1.0000e-04\n",
      "Epoch 236/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: 4.5687 - val_loss: 1.8218 - learning_rate: 1.0000e-04\n",
      "Epoch 237/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 4.8272 - val_loss: 1.8320 - learning_rate: 1.0000e-04\n",
      "Epoch 238/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 4.8679 - val_loss: 1.8864 - learning_rate: 1.0000e-04\n",
      "Epoch 239/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 5.1623 - val_loss: 1.8631 - learning_rate: 1.0000e-04\n",
      "Epoch 240/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 4.6821 - val_loss: 1.7573 - learning_rate: 1.0000e-04\n",
      "Epoch 241/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 5.0917 - val_loss: 1.6878 - learning_rate: 1.0000e-04\n",
      "Epoch 242/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 5.4297 - val_loss: 1.6846 - learning_rate: 1.0000e-04\n",
      "Epoch 243/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 5.6019 - val_loss: 1.6682 - learning_rate: 1.0000e-04\n",
      "Epoch 244/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 5.8430 - val_loss: 1.5931 - learning_rate: 1.0000e-04\n",
      "Epoch 245/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 5.9616 - val_loss: 1.5856 - learning_rate: 1.0000e-04\n",
      "Epoch 246/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 5.0886 - val_loss: 1.5904 - learning_rate: 1.0000e-04\n",
      "Epoch 247/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 5.7836 - val_loss: 1.5607 - learning_rate: 1.0000e-04\n",
      "Epoch 248/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 5.0571 - val_loss: 1.5314 - learning_rate: 1.0000e-04\n",
      "Epoch 249/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 4.7972 - val_loss: 1.4917 - learning_rate: 1.0000e-04\n",
      "Epoch 250/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 4.9615 - val_loss: 1.5202 - learning_rate: 1.0000e-04\n",
      "Epoch 251/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 3.8734 - val_loss: 1.5380 - learning_rate: 1.0000e-04\n",
      "Epoch 252/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 5.3096 - val_loss: 1.5646 - learning_rate: 1.0000e-04\n",
      "Epoch 253/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 4.8352 - val_loss: 1.4842 - learning_rate: 1.0000e-04\n",
      "Epoch 254/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 4.6473 - val_loss: 1.3986 - learning_rate: 1.0000e-04\n",
      "Epoch 255/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 4.8626 - val_loss: 1.3865 - learning_rate: 1.0000e-04\n",
      "Epoch 256/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 5.2361 - val_loss: 1.4038 - learning_rate: 1.0000e-04\n",
      "Epoch 257/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 5.0268 - val_loss: 1.3271 - learning_rate: 1.0000e-04\n",
      "Epoch 258/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 5.2191 - val_loss: 1.3182 - learning_rate: 1.0000e-04\n",
      "Epoch 259/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 4.4951 - val_loss: 1.3506 - learning_rate: 1.0000e-04\n",
      "Epoch 260/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 5.4235 - val_loss: 1.3635 - learning_rate: 1.0000e-04\n",
      "Epoch 261/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 4.8243 - val_loss: 1.3548 - learning_rate: 1.0000e-04\n",
      "Epoch 262/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 4.1539 - val_loss: 1.3496 - learning_rate: 1.0000e-04\n",
      "Epoch 263/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 4.0842 - val_loss: 1.3532 - learning_rate: 1.0000e-04\n",
      "Epoch 264/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 5.0364 - val_loss: 1.3058 - learning_rate: 1.0000e-04\n",
      "Epoch 265/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 4.3749 - val_loss: 1.3117 - learning_rate: 1.0000e-04\n",
      "Epoch 266/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 4.5129 - val_loss: 1.3369 - learning_rate: 1.0000e-04\n",
      "Epoch 267/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 4.0961 - val_loss: 1.2592 - learning_rate: 1.0000e-04\n",
      "Epoch 268/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 5.2757 - val_loss: 1.2110 - learning_rate: 1.0000e-04\n",
      "Epoch 269/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 4.4977 - val_loss: 1.1710 - learning_rate: 1.0000e-04\n",
      "Epoch 270/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 4.3740 - val_loss: 1.1538 - learning_rate: 1.0000e-04\n",
      "Epoch 271/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 4.5216 - val_loss: 1.1602 - learning_rate: 1.0000e-04\n",
      "Epoch 272/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 4.1939 - val_loss: 1.1942 - learning_rate: 1.0000e-04\n",
      "Epoch 273/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 4.4239 - val_loss: 1.1625 - learning_rate: 1.0000e-04\n",
      "Epoch 274/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 4.3431 - val_loss: 1.1320 - learning_rate: 1.0000e-04\n",
      "Epoch 275/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 4.9782 - val_loss: 1.1068 - learning_rate: 1.0000e-04\n",
      "Epoch 276/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 5.3155 - val_loss: 1.1990 - learning_rate: 1.0000e-04\n",
      "Epoch 277/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 4.3313 - val_loss: 1.1634 - learning_rate: 1.0000e-04\n",
      "Epoch 278/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.9190 - val_loss: 1.1062 - learning_rate: 1.0000e-04\n",
      "Epoch 279/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 4.2622 - val_loss: 1.0624 - learning_rate: 1.0000e-04\n",
      "Epoch 280/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 3.7224 - val_loss: 1.0293 - learning_rate: 1.0000e-04\n",
      "Epoch 281/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 5.2406 - val_loss: 1.0219 - learning_rate: 1.0000e-04\n",
      "Epoch 282/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 4.9546 - val_loss: 1.0309 - learning_rate: 1.0000e-04\n",
      "Epoch 283/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 4.5937 - val_loss: 1.0064 - learning_rate: 1.0000e-04\n",
      "Epoch 284/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 4.0971 - val_loss: 1.0378 - learning_rate: 1.0000e-04\n",
      "Epoch 285/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 3.8269 - val_loss: 1.0484 - learning_rate: 1.0000e-04\n",
      "Epoch 286/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 4.5922 - val_loss: 0.9866 - learning_rate: 1.0000e-04\n",
      "Epoch 287/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 4.4904 - val_loss: 0.9713 - learning_rate: 1.0000e-04\n",
      "Epoch 288/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 4.1590 - val_loss: 0.9869 - learning_rate: 1.0000e-04\n",
      "Epoch 289/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 3.9894 - val_loss: 1.0086 - learning_rate: 1.0000e-04\n",
      "Epoch 290/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 4.3338 - val_loss: 1.0165 - learning_rate: 1.0000e-04\n",
      "Epoch 291/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 4.3667 - val_loss: 0.9445 - learning_rate: 1.0000e-04\n",
      "Epoch 292/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 3.9212 - val_loss: 0.9428 - learning_rate: 1.0000e-04\n",
      "Epoch 293/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 4.4989 - val_loss: 0.9738 - learning_rate: 1.0000e-04\n",
      "Epoch 294/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 4.3638 - val_loss: 0.9136 - learning_rate: 1.0000e-04\n",
      "Epoch 295/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 3.8799 - val_loss: 0.9388 - learning_rate: 1.0000e-04\n",
      "Epoch 296/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 4.3172 - val_loss: 0.9087 - learning_rate: 1.0000e-04\n",
      "Epoch 297/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 4.2482 - val_loss: 0.8914 - learning_rate: 1.0000e-04\n",
      "Epoch 298/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 3.6911 - val_loss: 0.8437 - learning_rate: 1.0000e-04\n",
      "Epoch 299/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 4.1224 - val_loss: 0.8618 - learning_rate: 1.0000e-04\n",
      "Epoch 300/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 3.9805 - val_loss: 0.8417 - learning_rate: 1.0000e-04\n",
      "Epoch 301/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 3.6567 - val_loss: 0.8361 - learning_rate: 1.0000e-04\n",
      "Epoch 302/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 4.5678 - val_loss: 0.8184 - learning_rate: 1.0000e-04\n",
      "Epoch 303/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 3.5653 - val_loss: 0.8004 - learning_rate: 1.0000e-04\n",
      "Epoch 304/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 4.6794 - val_loss: 0.7718 - learning_rate: 1.0000e-04\n",
      "Epoch 305/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 4.0815 - val_loss: 0.7631 - learning_rate: 1.0000e-04\n",
      "Epoch 306/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 4.0428 - val_loss: 0.7773 - learning_rate: 1.0000e-04\n",
      "Epoch 307/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 3.8423 - val_loss: 0.8057 - learning_rate: 1.0000e-04\n",
      "Epoch 308/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 3.9317 - val_loss: 0.8137 - learning_rate: 1.0000e-04\n",
      "Epoch 309/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 3.6199 - val_loss: 0.7814 - learning_rate: 1.0000e-04\n",
      "Epoch 310/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 5.4984 - val_loss: 0.7653 - learning_rate: 1.0000e-04\n",
      "Epoch 311/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 3.7898 - val_loss: 0.7760 - learning_rate: 1.0000e-04\n",
      "Epoch 312/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 4.1522 - val_loss: 0.8224 - learning_rate: 1.0000e-04\n",
      "Epoch 313/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 4.1042 - val_loss: 0.8046 - learning_rate: 1.0000e-04\n",
      "Epoch 314/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 4.3831 - val_loss: 0.7445 - learning_rate: 1.0000e-04\n",
      "Epoch 315/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 4.1670 - val_loss: 0.7161 - learning_rate: 1.0000e-04\n",
      "Epoch 316/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 3.8331 - val_loss: 0.7122 - learning_rate: 1.0000e-04\n",
      "Epoch 317/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 4.2525 - val_loss: 0.7028 - learning_rate: 1.0000e-04\n",
      "Epoch 318/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 3.6514 - val_loss: 0.7733 - learning_rate: 1.0000e-04\n",
      "Epoch 319/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 3.9567 - val_loss: 0.7189 - learning_rate: 1.0000e-04\n",
      "Epoch 320/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 4.0914 - val_loss: 0.6670 - learning_rate: 1.0000e-04\n",
      "Epoch 321/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 3.7868 - val_loss: 0.6815 - learning_rate: 1.0000e-04\n",
      "Epoch 322/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 3.6543 - val_loss: 0.7689 - learning_rate: 1.0000e-04\n",
      "Epoch 323/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 3.5906 - val_loss: 0.7769 - learning_rate: 1.0000e-04\n",
      "Epoch 324/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 4.1018 - val_loss: 0.7271 - learning_rate: 1.0000e-04\n",
      "Epoch 325/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 3.8198 - val_loss: 0.7168 - learning_rate: 1.0000e-04\n",
      "Epoch 326/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 4.1110 - val_loss: 0.7400 - learning_rate: 1.0000e-04\n",
      "Epoch 327/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 3.5749 - val_loss: 0.7236 - learning_rate: 1.0000e-04\n",
      "Epoch 328/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 3.9765 - val_loss: 0.6921 - learning_rate: 1.0000e-04\n",
      "Epoch 329/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 3.3710 - val_loss: 0.6561 - learning_rate: 1.0000e-04\n",
      "Epoch 330/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 3.4885 - val_loss: 0.6315 - learning_rate: 1.0000e-04\n",
      "Epoch 331/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 3.3821 - val_loss: 0.6944 - learning_rate: 1.0000e-04\n",
      "Epoch 332/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 3.9716 - val_loss: 0.7229 - learning_rate: 1.0000e-04\n",
      "Epoch 333/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 3.2027 - val_loss: 0.6441 - learning_rate: 1.0000e-04\n",
      "Epoch 334/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 4.5480 - val_loss: 0.5956 - learning_rate: 1.0000e-04\n",
      "Epoch 335/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 3.2384 - val_loss: 0.6413 - learning_rate: 1.0000e-04\n",
      "Epoch 336/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.2841 - val_loss: 0.6667 - learning_rate: 1.0000e-04\n",
      "Epoch 337/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 3.7699 - val_loss: 0.6078 - learning_rate: 1.0000e-04\n",
      "Epoch 338/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 3.2641 - val_loss: 0.5835 - learning_rate: 1.0000e-04\n",
      "Epoch 339/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 3.8019 - val_loss: 0.6014 - learning_rate: 1.0000e-04\n",
      "Epoch 340/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 4.0306 - val_loss: 0.6445 - learning_rate: 1.0000e-04\n",
      "Epoch 341/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 3.7553 - val_loss: 0.7114 - learning_rate: 1.0000e-04\n",
      "Epoch 342/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 4.0339 - val_loss: 0.6025 - learning_rate: 1.0000e-04\n",
      "Epoch 343/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 3.6022 - val_loss: 0.5399 - learning_rate: 1.0000e-04\n",
      "Epoch 344/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 3.3346 - val_loss: 0.5664 - learning_rate: 1.0000e-04\n",
      "Epoch 345/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 4.2142 - val_loss: 0.5636 - learning_rate: 1.0000e-04\n",
      "Epoch 346/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 3.8718 - val_loss: 0.5559 - learning_rate: 1.0000e-04\n",
      "Epoch 347/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 3.2936 - val_loss: 0.5293 - learning_rate: 1.0000e-04\n",
      "Epoch 348/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 3.2596 - val_loss: 0.5790 - learning_rate: 1.0000e-04\n",
      "Epoch 349/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 3.4713 - val_loss: 0.6323 - learning_rate: 1.0000e-04\n",
      "Epoch 350/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 4.4769 - val_loss: 0.5893 - learning_rate: 1.0000e-04\n",
      "Epoch 351/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 3.8619 - val_loss: 0.5750 - learning_rate: 1.0000e-04\n",
      "Epoch 352/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 3.4450 - val_loss: 0.5746 - learning_rate: 1.0000e-04\n",
      "Epoch 353/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 3.8873 - val_loss: 0.6402 - learning_rate: 1.0000e-04\n",
      "Epoch 354/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 3.0889 - val_loss: 0.5741 - learning_rate: 1.0000e-04\n",
      "Epoch 355/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 3.5790 - val_loss: 0.5563 - learning_rate: 1.0000e-04\n",
      "Epoch 356/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: 3.6715 - val_loss: 0.6155 - learning_rate: 1.0000e-04\n",
      "Epoch 357/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.7588 \n",
      "Epoch 357: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 3.8092 - val_loss: 0.5628 - learning_rate: 1.0000e-04\n",
      "Epoch 358/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 4.1339 - val_loss: 0.5613 - learning_rate: 1.0000e-05\n",
      "Epoch 359/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 4.1916 - val_loss: 0.5540 - learning_rate: 1.0000e-05\n",
      "Epoch 360/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 4.0240 - val_loss: 0.5477 - learning_rate: 1.0000e-05\n",
      "Epoch 361/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 4.2031 - val_loss: 0.5454 - learning_rate: 1.0000e-05\n",
      "Epoch 362/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 3.9776 - val_loss: 0.5429 - learning_rate: 1.0000e-05\n",
      "Epoch 363/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 3.7237 - val_loss: 0.5406 - learning_rate: 1.0000e-05\n",
      "Epoch 364/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2.9941 - val_loss: 0.5406 - learning_rate: 1.0000e-05\n",
      "Epoch 365/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 3.5422 - val_loss: 0.5447 - learning_rate: 1.0000e-05\n",
      "Epoch 366/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 3.5138 - val_loss: 0.5421 - learning_rate: 1.0000e-05\n",
      "Epoch 367/500\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 161ms/step - loss: 3.8000\n",
      "Epoch 367: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 3.5400 - val_loss: 0.5362 - learning_rate: 1.0000e-05\n",
      "Epoch 368/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 3.4442 - val_loss: 0.5362 - learning_rate: 1.0000e-06\n",
      "Epoch 369/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 3.3571 - val_loss: 0.5370 - learning_rate: 1.0000e-06\n",
      "Epoch 370/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 3.4795 - val_loss: 0.5373 - learning_rate: 1.0000e-06\n",
      "Epoch 371/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.6775 - val_loss: 0.5374 - learning_rate: 1.0000e-06\n",
      "Epoch 372/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 3.2102 - val_loss: 0.5360 - learning_rate: 1.0000e-06\n",
      "Epoch 373/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 4.2296 - val_loss: 0.5348 - learning_rate: 1.0000e-06\n",
      "Epoch 374/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 3.3158 - val_loss: 0.5344 - learning_rate: 1.0000e-06\n",
      "Epoch 375/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 3.6209 - val_loss: 0.5343 - learning_rate: 1.0000e-06\n",
      "Epoch 376/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 3.6081 - val_loss: 0.5346 - learning_rate: 1.0000e-06\n",
      "Epoch 377/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.4627 - val_loss: 0.5347 - learning_rate: 1.0000e-06\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step \n",
      "Neural Network - RMSE: 833833423.18, R2: 0.4879\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "# Scaling fitur\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Log-transform target\n",
    "y_train_log = np.log1p(y_train)\n",
    "y_test_log = np.log1p(y_test)\n",
    "\n",
    "# Tambah kompleksitas model dan dropout\n",
    "def build_nn_improved(input_shape):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(128, activation='relu', input_shape=(input_shape,)),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.1),\n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), loss='mse')\n",
    "    return model\n",
    "\n",
    "model = build_nn_improved(X_train_scaled.shape[1])\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(patience=30, restore_best_weights=True, monitor='val_loss')\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, min_lr=1e-6, verbose=1)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train_log,\n",
    "    validation_split=0.3,\n",
    "    epochs=500,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop, reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "y_pred_log = model.predict(X_test_scaled).flatten()\n",
    "y_pred = np.expm1(y_pred_log)\n",
    "\n",
    "nn_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "nn_r2 = r2_score(y_test, y_pred)\n",
    "results[\"NN (Tensorflow)\"] = {\"RMSE\": rmse, \"R2\": r2}\n",
    "print(f\"Neural Network - RMSE: {rmse:.2f}, R2: {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2db81fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualisasi perbandingan\n",
    "labels = list(results.keys())\n",
    "rmse_values = [res[\"RMSE\"] for res in results.values()]\n",
    "r2_values = [res[\"R2\"] for res in results.values()]\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(labels, rmse_values, color='skyblue')\n",
    "plt.title(\"RMSE per Model\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(labels, r2_values, color='salmon')\n",
    "plt.title(\"R2 Score per Model\")\n",
    "plt.ylabel(\"R2 Score\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
